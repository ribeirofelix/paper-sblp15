\documentclass[english]{llncs}

\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{babel}

\title{Preserving Lexical Scoping While Embedding Languages}

\author{
Félix Ribeiro,
Hisham Muhammad,
André Murbach Maidl,
Roberto Ierusalimschy
}

\institute{
Department of Computer Science --
PUC-Rio -- Rio de Janeiro -- Brazil
\email{\{fribeiro,hisham,amaidl,roberto\}@inf.puc-rio.br}
}

\begin{document}

\maketitle

\begin{abstract}

There are various situations in which one may want to embed source code from
one language into another, for example when combining relational query
languages with application code or when performing staged meta-programming.
Typically, one will want to transfer data between these languages.
We propose an approach in which the embedded code shares variables with the
host language, preserving lexical scoping rules even after the code is
converted into an intermediate representation. We demonstrate this approach
through a module for meta-programming using Lua as both embedded and host
languages, which decompiles Lua functions to their AST form and can later
rebuild them preserving scoping rules of the decompilation site. Our method
requires no special annotation of functions to be translated and is
implemented as a library, requiring no source pre-processing or changes to
the host language execution environment.

\keywords{
Lua,
Domain Specific Languages,
Embedded Languages
}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:introduction}

Domain Specific Languages (DSLs) are a way to simplify the development
of programs through the aggregation of a specific knowledge into an
specific programming language.
A Domain Specific Language (DSL) is a concise programming language that
has a specific syntax to better express the semantics of a specific domain. 
For instance, we can use LaTeX for text processing, MATLAB for performing
numerical computations, and SQL for querying relational databases.

Sometimes programmers need to embed source code from one language into
a different language, and embedding a DSL into an application language
is a way to handle this problem.
For instance, we can combine relational query language with application
language to allow programmers to manipulate collections of several
different data types when they are developing applications that
access relational databases.

Embedding a DSL into an application language should allow programmers
to transfer data between these languages, a task that usually require
a data context to be executed.
Several programming languages do not have native support for this feature.
However, there are some solutions that allow meta-programming in these languages.
For instance, in Lua it is common to write code that we want to manipulate
inside a string and use functions from the standard library to evaluate this
code that is inside a string.
However, solutions like this have some inconveniences.
For instance, it is hard to detect syntactical errors while compiling the code.

Multi-Stage Programming (MSP) \cite{Taha1999MSP,Taha2004gentle,Taha2008gentle}
is a meta-programming approach that help embedding a programming language in
a host language with support to lexical scoping.
MSP handles embedded code through some language constructs that perform
program generation inside the host language.
One benefit of MSP is that it does not delay error verifications to run-time.
For instance, we can detect syntactical errors in the embedded code
during compile-time.
In fact, MSP is designed to detect type errors in the embedded code
during compile-time, preventing them to appear after the code is deployed.
Another benefit of MSP is that we can use program specialization to
reduce the costs of abstractions \cite{Taha1999MSP}.

Using MSP to embed languages inside imperative languages can be hard,
because in these languages programmers can use free variables outside
of the scope of their declarations \cite{Westbrook2010Mint}.
In purely functional languages we do not have this problem because these
languages do not have side effects \cite{Kameyama2008CSS}.

We propose an approach in which the embedded code shares variables with the
host language, preserving lexical scoping rules even after the code is
converted into an intermediate representation.
Our approach is an extension to MSP where the host language uses closures
to share data with the embedded language through variable references in
the generated code.
This means that our approach uses closures to ensure that free variables
are not used outside of the scope of their declarations.

We demonstrate this approach through a module for meta-programming using Lua
as both embedded and host languages.
Our module decompiles Lua functions to their Abstract Syntax Tree (AST) form
and can later rebuild them preserving scoping rules of the decompilation site.
For simplicity, our approach supports functions that only contain a
\texttt{return} statement.
We call these functions \emph{lambda functions}.

Our method requires no special annotation of functions to be translated and is
implemented as a library, requiring no source pre-processing or changes to
the host language execution environment.
When an AST describes a \emph{lambda function} that uses variables from an
external local scope, this AST includes the information about the context
where this \emph{lambda function} was defined.
When an AST stores more information than the syntax of the written code,
we say that this AST is an annotated AST.

We organize this paper in five sections.
In Section \ref{sec:related} we review related work in the field
of multi-stage programming.
In Section \ref{sec:lua2ast} we demonstrate our approach.
In Section \ref{sec:semantics} we formalize the semantics of our approach.
In Section \ref{sec:conclusion} we present our conclusions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:related}

Lisp \cite{McCarthy1960RFS} introduces a mechanism called \emph{quasiquotation}
that is useful for writing macros and some forms of program generation.
To do that, Lisp introduces the operator \texttt{`} to be used before an expression.
When the compiler finds this operator, it does not evaluate the expression,
but it creates an AST for that expression \cite{Bawden1999quasiquotation}.
The disadvantage of this approach is that is does not preserve lexical scoping.

Multi-Stage Programming \cite{Taha1999MSP,Taha2004gentle,Taha2008gentle} is
similar to the \emph{quasiquotation} mechanism introduced by Lisp,
but it takes lexical scoping into account.
MSP allows programmers to use meta-programming for improving code performance
or code expressiveness.
To do that, MSP introduces three constructs that programmers can use to
annotate code: brackets, escape, and run.
We will use MetaOCaml \cite{Calcagno2003implementing} to briefly explain
these constructs.
MetaOCaml is an OCaml extension with MSP support through these three staging
constructs.

Brackets, written \texttt{.<>.}, delay the execution of a computation:
\begin{verbatim}
    let x = 1 + 1;;
    let y = .< 1 + 1 >.;;
\end{verbatim}

In this example, \texttt{x} has type \texttt{int} and \texttt{y} has
type \texttt{int code} in MetaOCaml. 
This means that the expression \texttt{x + y} is invalid code in MetaOCaml,
as the types of both variables do not match.

Escapes, written \texttt{.~}, combine small delayed computations for building
bigger ones:
\begin{verbatim}
    let z = .< x + .~y >.;;
\end{verbatim}

In this example, the code \texttt{.< x + .~y >.} binds a new delayed computation
\texttt{2 + (1 + 1)} to \texttt{z}.

Run, written \texttt{.!}, compiles and executes staged code:
\begin{verbatim}
    let r = .!z;;
\end{verbatim}

In this example, the run annotation compiles and executes the code inside
\texttt{z}, assigning the integer \texttt{4} to \texttt{r}.

Implementing DSLs is the most interesting feature of MSP \cite{Czarnecki2004DSL}.
Programming languages are either interpreted or compiled.
Even though compiled languages usually produce code that run faster
due to optimizations, introducing code optimizations in the compiler
is not an easy task.
The MSP constructs allow programmers to write an interpreter for a
programming language and then annotate the code to stage the interpreter
into that execute code as faster as a compiled code.
The staged interpreter translates the DSL code to the host language code,
and that is the reason why it can run efficient code \cite{Taha2004gentle}.

Mint \cite{Westbrook2010Mint} is a MSP extension to Java.
Even though MSP ensures correctness while embedding languages using
purely functional languages, the same is not that straightforward when
we try to use MSP for embbeding imperative languages.
The problem of embedding a language in an imperative language is
related to side effects, as programmers can use free variables
undeliberatedly.
Mint extends the semantics of the escape construct to to impose
some restrictions on side effects, not allowing side effects to
appear inside a escape construct when these side effects interact
with delayed code.

LINQ (Language Integrated-Query) \cite{linq} is a set of resources that
extends C\#, allowing programmers to perform queries and manipulate data over
different kinds of data storage such as XML and MDF.
We can also use LINQ with data structures such as lists and arrays.

Terra \cite{DeVito2013Terra} is MSP language that is embedded in Lua
for high-performing computing.

Metalua \cite{metalua} is a Lua compiler that supports compile-time
meta-programming (CTMP), a mechanism that allows programmers to interact
with the compiler through a macro system \cite{Fleutot2007contrasting}.
Metalua extends Lua 5.1 to provide methods for transforming Lua
code into Abstract Syntax Trees (ASTs), but this code cannot contain
\emph{upvalues}.
In Lua, \emph{upvalues} are \emph{non-local variables}, that is,
they are free variables that are not defined in the local scope,
but they are often defined inside an anonymous function \cite{Ierusalimschy2006PIL}.
In the next section we will show that our approach can generate
the same AST that Metalua generates, but including information
about \emph{upvalues}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Lua2AST}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:lua2ast}

Lua2AST is a Lua module that takes a restricted form of Lua function, that we named lambda functions, and generates its AST in runtime.
Lambda functions are defined here as functions that only contain the return statement.
The expression contained in the return statement can be of any kind and can also use variables of the outer lexical scope.
In Lua, this kind of variables are called upvalues.
The process of generation uses externs libraries: luadec and lua-parser.
Lua-parser \cite{lua-parser} generates a Lua AST from a string with a valid Lua code.
Luadec \cite{luadec} is a Lua decompiler that takes a Lua binary chunk and returns a string with equivalent code.

One big difference from this work to the related works is that we use a decompiler and do not annotate the code.
Some advantages lie in the use of a decompiler: 
\begin{enumerate}
\item No modification in virtual machine; 
\item More transparent to the programmer; 
\item All the process is performed in runtime;
\item Lua's eval function can be used.
\end{enumerate}
In the following paragraphs we explain these advantages in more detail.

Since a decompiler is used there is no need to modify the Lua's virtual machine source code.
So, the library takes a runtime binary chunk and uses the decompiler to get an equivalent code.

Because the transformation is done via library, programmers do not need to annotate the code from which they want to generate the AST.
Thanks to that the process is more transparent to the developers and they do not need to learn any aditional syntax or rules.


Lua is a dynamic language and has powerfull features like eval functions, which  are frenquently used.
In order to keep these functions when using Lua2AST, all the process must be done at runtime.
But all we have at this stage to do that is the binary chunk. 
Then to get the AST we must decompile it.
With this, our approach of using a decompiler preserves powerfull features of the language, which would not be possible if we used a preprocessor instead.


%% TODO : detalhar o pq do uso do luadec - diferenciar dos related works
%% explicitando as vantagens de utilizar o LuaDec
%% Menos intruzivo no codigo fonte(nao precisam ser anotadas) e mais no background
%% nao tem modificacao na virtual machine 
%% linguagem eh dinamica - ela tem eval (alem de ser dinamicamente tipada) - facilidade provida pela linguagem
%% nossa abordagem ela integra bem com as caracteristicas dinamicas da linguagem
%% o q nao seria possivel se fosse feita atraves de preprocessador
%% pontuar q o processo inteiro ocorre em tempo de execucao
This module contains two principal functions: toAST e compile.
The first one generates an AST and the second one compiles an AST.

\subsection{Function toAST(func) }

The parameter func must be a lambda function.
The function's return is a Lua table that represents an AST.
If the received function uses upvalues the returned table will be an annotated AST,so that the upvalues can be evaluated properly.

The toAST(func) function calls the function luadec(arg) that belongs to libluadec, sending the function that will be transformed in AST as argument.
The return of the luadec(arg) is a string that represents the passed function code.
This string is sent to the parse function of lua-parser library and it returns the AST that represents the code.

The received AST is traversed once.
Firstly we find the parameters of the function and store them in a set.
Later, we localize the free variables of the  function and when they are found a execution code lookup is made with the standard library debug.

The lookup consists in going through the upvalues that belongs to the function that was sent to toAST in order to find the variable of the same name.
When the variable is found, we do the AST annotation process.

To do this annotation in our AST we use the function upvaluejoin, that also belongs to the debug library.
This function joins two upvalues of distinct functions.
But, to use this function, we need another one to join the upvalues. To do so, we created the functions that follows:


\begin{verbatim}
local function newclosure()
    local temp
    return function () return temp end
end
\end{verbatim}

So, when an upvalue is found, the newclosure function is called, then its return is assigned to a variable and the found upvalue is joint to the temp upvalue.
After pulling them together, we generate an unique identifier to the function returned by newclosure.
We replace in the AST the node that identifies the free variable by an upvalue node.
In this node is inserted the function with unique identifier generated by upvalue.


The following example illustrates the use of the toAST function:


\begin{verbatim}
local last = require "lua-to-AST"

local y = 1
ast = last.toAST(function(x) return x + y end )
last.print(ast)
\end{verbatim}


The program's output will be the AST print, as below:
%% Verificar higienizacao de variaveis
\begin{verbatim}
{ `Function{ { `Id "x" },
      { `Return{ `Op{ "add", `Id "x", `UpValue "clo_0"}}}}}}
\end{verbatim}


\subsection{Function compile(ast) }


%% completar exemplo da secao anterior
%% mostrar string interna 
This function receives as argument the AST generated by toAST and returns the function that this AST describes.

The AST received is encapsulated in a return node and then a string with correspondent Lua code is generated.Using the AST above to examplify, its correspondent string would be as follows:


%% TODO : higenizacao
\begin{verbatim}
"function(x) return x + closures["clo_0"]() end"
\end{verbatim}

This string is sent to the loadstring function.
The function compile returns the result of loadstring.
In this way the user can utilize the returned function that is the compilation of the AST.
Bellow we show an example of using the compile function, it uses the AST that was previously generated.


\begin{verbatim}
f = last.compile(ast)
print(f(2)) -- output: 3
y = 40
print(f(2)) -- output: 42
\end{verbatim}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semantics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:semantics}

\label{sec:semantics}

In this section, we specify below the behavior of toAST() and compile()
by using the formalization of a subset of Lua semantics, presented
in \cite{DeVito2013Terra} as Lua Core. We use the same formal framework
of that work in order to properly compare and contrast our approach
for multi-stage programming to that employed by Terra.

Lua Core depicts the notions of lexical scoping, closures and side-effects
present in Lua, and is therefore mostly sufficient for our purposes.
We extend this specification with an arbitrary ``binary operator''
expression, mimicking Lua operators supported by Lua2AST. This way,
we have a recursive rule through which we can model Lua expressions
as trees, to be later converted to ASTs. We also include toAST() and
compile() as core language operations so we can specify their semantics
separately from plain functions.

\begin{figure}[t]
\begin{eqnarray*}
e & = & b\,|\, x\,|\,\mbox{let \ensuremath{x=e}\,\ in\,\ensuremath{e}}\,|\, x\coloneqq e\,|\, e(e)\,|\,\mbox{fun}(x)\{e\}\,|\, e\mbox{ op }e\,|\,\mbox{toAST}(e)\,|\,\mbox{compile}(a)\\
v & = & b\,|\,\left\langle \Gamma,x,e\right\rangle \,|\, a\\
a & = & [\mbox{fn\,\ensuremath{x}\,\ensuremath{a}}]\,|\,[\mbox{base \ensuremath{b}}]\,|\,[\mbox{var}\, x\,\left\langle \Gamma,x,e\right\rangle ]\,|\,[\mbox{op\,\ensuremath{a}\,\ensuremath{a}}]
\end{eqnarray*}
\protect\caption{\label{fig:LuaCoreSyntax}Syntax of our version of Lua Core, extended
with constructs to specify Lua2AST}
\end{figure}

\begin{figure}[!t]
{\footnotesize{}}%
\begin{minipage}[t]{0.59\columnwidth}%
{\footnotesize{}
\[
v,\Sigma\overset{L}{\rightarrow}v,\Sigma\textsc{ (LVal)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\Sigma=(\Gamma,S)}{x,\Sigma\overset{L}{\rightarrow}S(\Gamma(x)),\Sigma}\textsc{ (LVar)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
e_{1},\Sigma_{1}\overset{L}{\rightarrow}v_{1},(\Gamma_{2},S_{2})\,\,\,\,\,\,\,\, p\,\mbox{fresh}\\
e_{2},(\Gamma_{2}[x\leftarrow p],S_{2}[p\leftarrow v_{1}])\overset{L}{\rightarrow}v_{2},(\Gamma_{3},S_{3})
\end{array}}{\mbox{let \ensuremath{x=e_{1}}\,\ in\,\ensuremath{e_{2}}},\Sigma_{1}\overset{L}{\rightarrow}v_{2},(\Gamma_{2},S_{3})}\textsc{ (LLet)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
e_{1},\Sigma_{1}\overset{L}{\rightarrow}\left\langle \Gamma_{1},x,e_{3}\right\rangle ,\Sigma_{2}\\
e_{2},\Sigma_{2}\overset{L}{\rightarrow}v_{1},(\Gamma_{3},S_{3})\,\,\,\,\,\,\,\,\mbox{\ensuremath{p}\ fresh}\\
e_{3},(\Gamma_{1}[x\leftarrow p],S_{3}[p\leftarrow v_{1}])\overset{L}{\rightarrow}v_{2},(\Gamma_{4},S_{4})
\end{array}}{e_{1}(e_{2}),\Sigma_{1}\overset{L}{\rightarrow}v_{2},(\Gamma_{3},S_{4})}\textsc{ (LApp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e_{1},\Sigma_{1}\overset{L}{\rightarrow}v_{1},(\Gamma,S)\,\,\,\,\,\,\,\,\Gamma(x)=p}{x\coloneqq e,\Sigma\overset{L}{\rightarrow}v,(\Gamma,S[p\leftarrow v])}\textsc{ (LAsn)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\Sigma=(\Gamma,S)}{\mbox{fun(\ensuremath{x})\{\ensuremath{e}\}},\Sigma\overset{L}{\rightarrow}\left\langle \Gamma,x,e\right\rangle ,\Sigma}\textsc{ (LFun)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
e_{1},\Sigma_{1}\overset{L}{\rightarrow}v_{1},\Sigma_{2}\,\,\,\,\,\,\,\, e_{2},\Sigma_{2}\overset{L}{\rightarrow}v_{2},\Sigma_{3}\\
v_{3}=Op(v_{1},v_{2})
\end{array}}{e_{1}\mbox{\, op\,}e_{2},\Sigma_{1}\overset{L}{\rightarrow}v_{3},\Sigma_{3}}\textsc{ (LOp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e_{1},\Sigma_{1}\overset{L}{\rightarrow}\left\langle \Gamma,x,e_{2}\right\rangle ,\Sigma_{2}\,\,\,\,\,\,\,\,\left\langle \Gamma,x,e_{2}\right\rangle ,\Sigma_{2}\overset{D}{\rightarrow}a}{\mbox{toAST(\ensuremath{e_{1}})},\Sigma_{1}\overset{L}{\rightarrow}a,\Sigma_{2}}\textsc{ (LAst)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{a,\Sigma_{1}\overset{C}{\rightarrow}e,\Sigma_{2}}{\mbox{compile(\ensuremath{a})},\Sigma_{1}\rightarrow e,\Sigma_{2}}\textsc{ (LComp)}
\]
}%
\end{minipage}{\footnotesize{}}%
\begin{minipage}[t]{0.4\columnwidth}%
{\footnotesize{}
\[
b,\Sigma\overset{D}{\rightarrow}[\mbox{base }b]\textsc{ (DBase)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
\Sigma=(\Gamma,S)\\
x'\,\mbox{fresh}
\end{array}}{x,\Sigma\overset{D}{\rightarrow}[\mbox{var }x'\,\left\langle \Gamma,\_,x\right\rangle ]}\textsc{ (DVar)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e_{1},\Sigma\overset{D}{\rightarrow}a_{1}\,\,\,\,\,\,\,\, e_{2},\Sigma\overset{D}{\rightarrow}a_{2}}{e_{1}\mbox{ op }e_{2},\Sigma\overset{D}{\rightarrow}[\mbox{op\,\ensuremath{a_{1}\,}\ensuremath{a_{2}}}]}\textsc{ (DOp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e,\Sigma\overset{D}{\rightarrow}a}{\left\langle \Gamma,x,e\right\rangle ,\Sigma\overset{D}{\rightarrow}[\mbox{fn }x\, a]}\textsc{ (DFn)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
[\mbox{base \ensuremath{b}}],\Sigma\overset{C}{\rightarrow}b,\Sigma\textsc{ (CBase)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
\Sigma_{1}=(\Gamma,S)\\
p\,\mbox{fresh}\\
\Sigma_{2}=(\Gamma[x'\leftarrow p],S[p\leftarrow f])
\end{array}}{[\mbox{var }x'\, f],\Sigma_{1}\overset{C}{\rightarrow}x'(\_),\Sigma_{2}}\textsc{ (CVar)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{a_{1},\Sigma_{1}\overset{C}{\rightarrow}e_{1},\Sigma_{2}\,\,\,\,\,\,\,\, a_{2},\Sigma_{2}\overset{C}{\rightarrow}e_{2},\Sigma_{3}}{[\mbox{op\,\ensuremath{a_{1}}\ensuremath{\, a_{2}}}],\Sigma_{1}\overset{C}{\rightarrow}e_{1}\mbox{ op }e_{2},\Sigma_{3}}\textsc{ (COp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
\Sigma_{1}=(\Gamma_{1},S_{1})\\
a,\Sigma_{1}\overset{C}{\rightarrow}e,(\Gamma_{2},S_{2})
\end{array}}{[\mbox{fn }x\, a],\Sigma_{1}\overset{C}{\rightarrow}\left\langle \Gamma_{2},x,e\right\rangle ,(\Gamma_{1},S_{2})}\textsc{ (CFn)}
\]
}%
\end{minipage}{\footnotesize \par}

\protect\caption{\label{fig:Semantics}Rules $\protect\overset{L}{\rightarrow}$ for
the evaluation of Lua expressions, $\protect\overset{D}{\rightarrow}$
for decompiling Lua expressions into ASTs, and $\protect\overset{C}{\rightarrow}$
for compiling ASTs back into expressions.}
\end{figure}



The syntax of our version of Lua Core is presented in Figure \ref{fig:LuaCoreSyntax}.
Lua expressions ($e$) can be base values ($b$), variables ($x$),
a scoped variable definition ($\mbox{let \ensuremath{x=e}\,\ in\,\ensuremath{e}}$,
with $e;e$ as sugar for $\mbox{let \ensuremath{\_=e}\,\ in\,\ensuremath{e}}$),
a variable assignment ($x\coloneqq e$), an application ($e(e)$),
a function definition ($\mbox{fun}(x)\{e\}$) or an operation on expressions
($e\mbox{ op }e$, with semantics defined by a function $Op$). We
extend this by adding operations \emph{toAST($e$)} and \emph{compile($a$)}.
Lua values ($v$) can be base values ($b$), closures ($\left\langle \Gamma,x,e\right\rangle $)
or Lua ASTs ($a$). A Lua AST for a function consists of a root node
($[\mbox{fn\,\ensuremath{x}\,\ensuremath{a}}]$) which may contain
nodes that wrap base values\emph{ }($[\mbox{base }b]$\emph{), }variables
($[\mbox{var }x\,\left\langle \Gamma,x,e\right\rangle ]$) and operations
($[\mbox{op}\, a\, a]$).

In Figure \ref{fig:Semantics}, we present the rules for evaluating
Lua Core over an environment $\Sigma$, which is a tuple $(\Gamma,S)$
containing a namespace $\Gamma:x\rightarrow p$ and a store $S:p\rightarrow v$
(where $p$ are memory positions). We use $\overset{L}{\rightarrow}$
for the evaluation of Lua expressions as in \cite{DeVito2013Terra};
where rules have the same names, they have the same semantics as those
presented in that work. We added rules \textsc{LOp} for the binary
operation, \textsc{LAst} for the $toAST()$ function and \textsc{LComp}
for the \emph{compile}() function.

We also add two other relations: rules for decompiling a Lua function
into an AST ($\overset{D}{\rightarrow}:(e\times\Sigma)\rightarrow a$)
and rules for compiling ASTs back into Lua functions ($\overset{C}{\rightarrow}:(a\times\Sigma)\rightarrow(e\times\Sigma)$).
In our formalization, decompiling the function produces an AST but
does not affect the environment; all values produced are stored in
the AST itself. Compiling returns an environment with an unmodified
namespace and a modified store which includes the required closures. 

Note that $\overset{D}{\rightarrow}$ is defined only for variables
(\textsc{DVar}), base values (\textsc{DBase}), the binary operator
(\textsc{DOp}), and the initial function (\textsc{DFn}), mirroring
the implementation of \emph{toAST}() in LuaToAST. Its rules deconstruct
the body of the function and build the corresponding AST. Of particular
interest is rule \textsc{DVar}, which stores in the AST node a fresh
variable $x'$ (i.e. one guaranteed not to exist in $\Gamma$) and
a newly created closure, which returns the value of $x$ given the
original function's environment. In the complementary rule \textsc{CVar},
this new variable $x'$ is assigned in the resulting environment to
hold the node's closure $f$. Note in rule \textsc{CFn} that the derived
namespace $\Gamma_{2}$ is used only in the resulting closure, whereas
the derived store $S_{2}$ is used in the resulting environment. In
$\Gamma_{2}$, all variable references that existed in the original
function that was decompiled and now recompiled were replaced by calls
to newly-created closures that merely return the value of the corresponding
variables.

These closures use the original namespace from decompilation time
($\Gamma$ in \textsc{DVar}), so the variable references are bound
to the addresses they have in the lexical scope where decompilation
takes place. Any variable $x$ stored in an AST will only be evaluated
when the compiled function returned by $compile(a)$ is called, and
the call to wrapper closure $x'()$ will ensure that $x$ is tied
to its original namespace.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:conclusion}

In this work we presented an approach for multi-stage programming through
which the lexical scope of variables can be preserved, by replacing
variable references in the generated representation of the embedded language
with closures from the host language. When the intermediate representation
is later converted into executable form, calls to these closures are
produced, ensuring access to the variable in the correct context.

We implemented a module that demonstrates this approach.
Our implementation uses a decompiler to convert, at runtime, Lua
functions into an abstract syntax tree form decorated with
closures that capture the lexical environment of free variables.
The module is then able to compile the AST back into Lua,
ensuring that the resulting function accesses the correct variables
even if compiled at a different call site.

The technique we present here is general, and its core principle
is not dependent on decompilation or on specificities of Lua.
It could be implemented in other languages using other methods,
such as source code pre-processing. However, the dynamic manipulation
of function objects, as opposed to compile-time manipulation of the
source tree, allows us to perform multi-stage programming dynamically,
operating on any suitable functions, even if they were created at run-time.
This is particularly useful for dynamic languages which provide
\texttt{eval}-like functionality, as is the case of Lua, with
the \texttt{dostring()} function of its standard library.

Our implementation also exploited Lua's facilities for manipulating
a closure's symbol table, which allowed the construction of the
generated functions purely through manipulation of Lua function
objects, without having to resort to low-level bytecode generation.
The only bytecode-level manipulation performed by LuaToAST is
read-only, and is restricted to the decompiler module. The
implementation did not require any modifications to the Lua VM.

We also specified the operational semantics for the transformations
performed by LuaToAST, in order to show how the lexical environment
of variables is correctly preserved, and to properly contrast it with
related work from the literature on multi-stage programming.

This work presents many possibilities for future extensions. The current
implementation is a proof-of-concept that demonstrates the technique,
and can be extended to support a wider range of Lua functions, by
supporting more of the host language's grammar. Another future work
we envision is the development of different code-generation back-ends,
supporting other languages. This would allow, for example, using
Lua functions for writing prepared statements for database query
languages.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{splncs_srt}
\bibliography{sblp2015}

\end{document}
