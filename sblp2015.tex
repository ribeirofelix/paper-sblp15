\documentclass[english]{llncs}

\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{babel}

\title{Preserving Lexical Scoping\\
When Dynamically Embedding Languages}

\author{
Félix Ribeiro,
Hisham Muhammad,\\
André Murbach Maidl,
Roberto Ierusalimschy
}

\institute{
Department of Computer Science --
PUC-Rio -- Rio de Janeiro -- Brazil
\email{\{fribeiro,hisham,amaidl,roberto\}@inf.puc-rio.br}
}

\begin{document}

\maketitle

\begin{abstract}

There are various situations in which one may want to embed source code from
one language into another, for example when combining relational query
languages with application code or when performing staged meta-programming.
Typically, one will want to transfer data between these languages.
We propose an approach in which the embedded code shares variables with the
host language, preserving lexical scoping rules even after the code is
converted into an intermediate representation. We demonstrate this approach
through a module for meta-programming using Lua as both embedded and host
languages, which decompiles Lua functions to their AST form and can later
rebuild them preserving scoping rules of the decompilation site. Our method
requires no special annotation of functions to be translated and is
implemented as a library, requiring no source pre-processing or changes to
the host language execution environment.

\keywords{
Lua,
Domain-Specific Languages,
Embedded Languages
}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:introduction}

Domain-Specific Languages (DSLs) are a way to simplify the development
of programs through the aggregation of domain knowledge into a
programming language.
A Domain-Specific Language is a programming language that
includes features to express the semantics of a domain,
often adding specific syntax.
Examples of DSLs are \TeX{} for text processing, MATLAB for performing
numerical computations, SQL for querying relational databases and
regular expressions for pattern matching in text.

The use of DSLs frequently happens in combination with other languages, so
that some aspects of a problem are handled with the DSL while other parts are
developed in a general-purpose language \cite{Fowler:2010:DSL:1809745}. One
way to do this is to embed source code written in the domain-specific language
into the source code of the application, which is written in another language.
We have then the notion of a \emph{host language} and an \emph{embedded language}.
SQL and regular expressions are examples of languages which are often used in this fashion.

Embedding source code of one language into another poses challenges.
Typically, a language parser does not have support for handling
chunks of code written in another language intermixed with the source
code. Common approaches to handle the source code of two languages
in a single source file are to either pull the processing back to a
step prior to the parsing of the main language, using pre-processing,
or to push it forward by storing the code written in the embedded
language as strings in the host language source code, which are
sent to the embedded language for processing only at run time.

This approach of storing code as strings, while popular, has some inconveniences.
For instance, it is not possible to detect syntactical errors while compiling the code.
Embedding languages should also allow programmers to transfer data
between these languages, taking care to keep data in sync.
For these reasons, solutions based on meta-programming, where the
embedded language can be manipulated at a higher level of abstraction
than strings, are more interesting.

Multi-Stage Programming (MSP) \cite{Taha1999MSP,Taha2004gentle,Taha2008gentle}
is a meta-programming approach that helps embedding a programming language in
a host language in a well-organized way.
It defines constructs for quoting and escaping source code
that produce code objects, which are valid objects stored in the host
language but can also be invoked to execute the embedded language.
A major benefit of MSP is that it does not delay error verification to run-time.
One can detect syntactical errors and even type errors in the embedded code
during compile-time.
Another benefit of MSP is that we can use program specialization to
reduce the costs of abstractions \cite{Taha1999MSP}.

Using MSP to embed languages inside imperative languages can be hard,
because in these languages programmers can move code objects so they
are used outside of the scope of the binder of their free variables
\cite{Westbrook2010Mint}.
In purely functional languages we do not have this problem 
due to the absence of side effects \cite{Kameyama2008CSS}.

In this work, we propose an approach for meta-programming
in which the embedded code shares variables with the
host language, preserving lexical scoping rules even after the code is
converted into an intermediate representation.
In our proposed method, the host language uses closures
to share data with the embedded language, replacing variable references
with function calls in the generated code.
This way, we ensure that variables always match the scope of their declarations.

We demonstrate this approach through a module for meta-programming using Lua
as both embedded and host languages.
Our module decompiles Lua functions to their Abstract Syntax Tree (AST) form
and can later rebuild them preserving scoping rules of the decompilation site.
For simplicity, our implementation only supports functions that contain
a single expression.
We call these functions \emph{lambda functions}.

Our method requires no special annotation of functions to be translated and is
implemented as a library, requiring no source pre-processing or changes to
the host language execution environment.
When an AST describes a function that uses variables from an
external local scope, it includes information about the context
where this function was defined.

We organize this paper in five sections.
In Section \ref{sec:related} we review related work in the field
of multi-stage programming.
In Section \ref{sec:lua2ast} we demonstrate our approach.
In Section \ref{sec:semantics} we formalize the semantics of our approach.
In Section \ref{sec:conclusion} we present our conclusions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:related}

Meta-programming is the concept of writing programs that manipulate
program code as data, producing other programs. This allows programmers
to improve code performance or expressiveness by defining transformations over code.
Lisp \cite{McCarthy1960RFS} pioneered meta-programming by introducing
a mechanism of \emph{quotation}: expressions marked with the operator \texttt{'}
are not evaluated, and are treated as data.
Later Lisp dialects like Common Lisp and Scheme include \emph{quasi-quotation},
represented with the operator \texttt{`}, that allows parts of the quoted expression
to be ``escaped'' (with the  \texttt{,} operator). The combination of
quasi-quotation and escaping powers the macro system of those languages \cite{Bawden1999quasiquotation}.
This feature, however, does not preserve scoping rules.

Multi-Stage Programming \cite{Taha1999MSP,Taha2004gentle,Taha2008gentle} is
similar to the quasi-quotation mechanism,
but it takes lexical scoping into account.
It features three constructs that programmers can use to
annotate code: \emph{brackets}, \emph{escape}, and \emph{run}.
We will use MetaOCaml \cite{Calcagno2003implementing}, an OCaml extension
with MSP support through these three staging constructs, to briefly explain
these constructs. \emph{Brackets}, marked with \texttt{.<>.}, avoid the execution of a computation,
constructing an object instead that represents the marked block of code:
\begin{verbatim}
    let x = 1 + 1;;
    let y = .< 1 + 1 >.;;
\end{verbatim}

In the above example, \texttt{x} has type \texttt{int} and \texttt{y} has
type \texttt{int code}. 
This means that the expression \texttt{x + y} is invalid code in MetaOCaml,
as the types of both variables do not match. \emph{Escapes}, marked as \texttt{.\~}, combine small delayed computations for building
bigger ones:
\begin{verbatim}
    let z = .< x + .~y >.;;
\end{verbatim}

Here, the code \texttt{.< x + .\~{}y >.} binds a new delayed computation
\texttt{2 + (1 + 1)} to \texttt{z}. \emph{Run}, using the prefix operator \texttt{.!}, executes staged code.
In the example below, the program will compile and execute the code inside
\texttt{z}, assigning the integer \texttt{4} to \texttt{r}:

\begin{verbatim}
    let r = .!z;;
\end{verbatim}

Implementing DSLs is one of the most interesting applications of MSP \cite{Czarnecki2004DSL}.
Implementing efficient DSLs, either as interpreters or as compilers,
is not an easy task.
The MSP constructs allow programmers to implement a DSL as
a staged interpreter, which translates the DSL code to the host language code,
allowing DSLs to run as efficiently as the host code, taking advantage
of the optimizations of the underlying compiler \cite{Taha2004gentle}.

Mint \cite{Westbrook2010Mint} is a MSP extension to Java.
Even though MSP ensures correctness while embedding languages using
purely functional languages, the same is not that straightforward when
we try to use MSP for embbeding imperative languages.
The problem of embedding a language in an imperative language is
related to side effects, as programmers can move code objects
beyond the bound scope of free variables inadvertedly, a problem
known as scope extrusion.
Mint extends the semantics of the escape construct to impose
some restrictions on side effects, not allowing side effects to
appear inside a escape construct when these side effects interact
with delayed code.

% TODO: Mint example?
% (illustrate scope extrusion problem / how it solves it)

LINQ (Language Integrated-Query) \cite{linq} is a set of features that
extends C\#, allowing programmers to perform queries and manipulate data over
different kinds of data storage such as XML and MDF.
One can also use LINQ with data structures such as lists and arrays.

In .NET, C\# and Visual Basic define a restricted type of anonymous
function called an \emph{expression lambda}, which is a function that
consists of a single expression. LINQ works as an embedded DSL
\cite{Fowler:2010:DSL:1809745} where anonymous functions are used
extensively, and was the motivating use case for the introduction
of expression lambdas. When one assigns an expression lambda to a variable
of type \texttt{Expression<TDelegate>}, .NET creates an AST
corresponding to that expression, called an \emph{expression tree}
\footnote{Note that in C\# parlance, \emph{lambda expression} is a
more general term that can refer to both single-expression anonymous functions
called \emph{expression lambdas} and multi-statement functions called
\emph{statement lambdas}. Conversion to expression trees is only supported for
expression lambdas.}. Expression trees can also be created 
programatically, manipulating node objects via the API of the
\texttt{Expression} class.

\begin{figure}[t]
\begin{verbatim}
 1    class Program {
 2      delegate int sumY (int arg);
 3      Expression <sumY> boo () {
 4        int y = 1;
 5        Expression <sumY> treesumY = x => x + y;
 6        y = y + 1;
 7        return treesumY;
 8      }
 9      int foo () {
10        int y = 10;
11        Expression <sumY> ret = boo();
12        return ret.Compile()(40); // returns 42
13      }
14    }
\end{verbatim}
\protect\caption{\label{fig:ExpressionTrees}Lexical scoping in variables
referenced in expression trees in C\#.}
\end{figure}

Expression lambdas can access external local variables, and they respect
lexical scope, regardless if they are used to declare anonymous functions or
only to produce an expression tree. Figure
\ref{fig:ExpressionTrees} illustrates how lexical scoping is preserved in
expression trees. Free variable \texttt{y} in line 5 references the declaration
from line 4, even when the expression tree returned in line 11 is compiled
into a function in line 12.

Terra \cite{DeVito2013Terra} is a multi-stage language for high-performance
computing. It uses Lua as a host language and defines extensions
for staged computation. Lua functions that run in the Lua interpreter are
declared using standard Lua syntax, with the \texttt{function} construct.
Staged code is declared as Terra functions, using the \texttt{terra}
statement. Terra functions use similar syntax to Lua, but they are statically
typed and compiled into native code using LLVM. Lua code can manipulate Terra
types and functions as Lua objects. Terra also features a \texttt{quote} statement
for quoting blocks of Terra code as expression objects and brackets
(\texttt{[]}) as the escape operator for evaluating Lua code inside a Terra
function.

When a Terra function is declared, all Lua expressions escaped inside it
and Lua variables are replaced by the results of their evaluation.
A Terra function, therefore, does not form a closure with
respect to free Lua variables. This design trades lexical scoping for the
guarantee that compiled Terra code does not need to call back into the Lua
interpreter during execution.

Metalua \cite{metalua} is a Lua compiler that supports compile-time
meta-programming, a mechanism that allows programmers to interact
with the compiler through a macro system \cite{Fleutot2007contrasting}.
Metalua extends Lua 5.1 to provide methods for transforming Lua
code into Abstract Syntax Trees, but this code cannot contain
references to local variables of an outer scope.

Our implementation generates program ASTs in the same format as
Metalua, but including information about enclosing local variables. While Metalua
handles arbitrary Lua code syntactically marked for quoting, our module
operates only on restricted functions, but requires no quoting.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Lua2AST}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:lua2ast}

Lua2AST is a Lua module that is able to generate ASTs given a restricted form of Lua functions, that we named lambda functions.
Lambda functions are defined as functions that contain in its body a single \texttt{return} statement containing an expression.
This expression can be of any kind and can also use variables of the outer lexical scope.

Lua supports functions as a first-class value. Function objects are proper closures, and are internally implemented by
storing along with each function a internal set of boxed references any \texttt{local} variables belonging to outer
lexical scopes. In Lua, these references are called \emph{upvalues} \cite{Ierusalimschy2006PIL}.
Upvalues implement proper lexical scoping and are generally transparent to the Lua programmer,
but they can be directly manipulated through Lua's C API and through its debug API.
Lua2AST can produce a Lua function object given an AST, and references to variables
in the resulting function match the lexical scoping rules of the call site where the
AST was originally generated. As we will see below, this is done using the debug API
to correct upvalue references in the generated code.

Lua2AST uses two external Lua libraries in its implementation: LuaDec and Lua-Parser.
Luadec \cite{luadec} is a Lua decompiler that takes a Lua binary chunk and returns a string with equivalent Lua source code.
Lua-Parser \cite{lua-parser} generates a Lua table representing the code AST given a string of Lua source code.
Lua2AST works by decompiling the input function with LuaDec, producing an AST with Lua-Parser
and finally resolving upvalue references in this AST, producing an annotated AST
with additional information that allows the library to recreate the function's original
environment.

Our approach to preserve variable references is to generate auxiliary closures
when converting the function into AST format. These auxiliary closures are
stored in the AST data structure. When compiling the AST back into a function,
variable references are replaced by function calls to these closures.

This approach presents two major advantages to usual methods for adding staged computation to existing languages.
Firstly, our implementation is done entirely as a library. 
By internally using a decompiler, we can operate directly on Lua function objects
without having to use a source code preprocessor.
This results in a non-intrusive approach: we did not need to create language extensions and we did not need to modify the Lua virtual machine.

Secondly, our approach is particularly suitable for a dynamic language.
If Lua2AST was implemented as a static pass over the input source code,
it would not be possible to transform dynamically-loaded functions into ASTs.
Since Lua2AST operates entirely at runtime, we are able to operate over
any suitable lambda function, including dynamically-generated Lua functions,
such as those loaded during program execution using the \texttt{dostring} function.

Below, we will discuss the implementation in further detail, covering the two main functions
of the Lua2AST API: \texttt{lua2ast.toAST} and \texttt{lua2ast.compile}.

\subsection{Function lua2ast.toAST(\emph{func})}

The function \texttt{toAST} generates an AST from a Lua function.
It takes a Lua function as a parameter, which must be a lambda function.
The function's return is a Lua table that represents an AST.
This table follows a standardized format for Lua ASTs that was originally defined by the Metalua project \cite{metalua}.
If the received function uses upvalues, this AST will be decorated with additional data, so that upvalue references
can be later reconstructed.

The function \texttt{toAST} initially calls the LuaDec decompiler to produce a source code representation of the given function.
This string is sent to the \texttt{parse} function of the Lua-Parser library, producing the AST that represents the code.
The AST as returned by Lua-Parser, however, would not be sufficient to reconstruct the function with proper scoping rules.
Simply rebuilding the plain AST into source code and loading into Lua would produce a function where all local variables
of outer scopes would turn into global variable references, since in Lua undeclared variables are treated as globals
by default.

The next step, therefore, is to detect locals of outer scopes and to annotate them in the AST. 
This is done by scanning variable references in the AST and matching them to the list of upvalues
of the function object.
Firstly, we find the parameters of the function and store them in a set.
Then, we locate the free variables of the function, which are indentifiers in our expression tree that are not in the set of function arguments.
These free identifiers may be references to outer locals or references to global variables.
Any outer local will have a matching entry in the internal list of upvalues of the closure.
We look for this entry using \texttt{debug.getupvalue()}, a function of Lua's standard library
that allows us to perform introspection of a function's upvalues.
When the variable is found, we decorate the AST node.

To do this decoration in our AST, we create a closure which will hold a reference
to our desired variable.
To do so, we use the following helper function:

\begin{verbatim}
local function newclosure()
    local temp
    return function () return temp end
end
\end{verbatim}

This function produces a new closure that contains an upvalue and merely returns it.
We then use the function \texttt{debug.upvaluejoin()}, also from the standard library.
This function gets an upvalue from a Lua closure and make it refer to another upvalue
from a different function. 
We take the upvalue from our desired variable and join it with the upvalue for the \texttt{temp} variable of our newly-created closure.
We then store this auxiliary closure in the AST node that identifies the free variable.

Figure \ref{fig:Lua2ASTExample} illustrates the use of the \texttt{lua2ast.toAST()} function.
The Lua code on this example operates equivalently to the code on Figure \ref{fig:ExpressionTrees}.
For illustration purposes, the code also calls \texttt{lua2ast.print()}, which dumps the AST in textual format,
following the syntax of Metalua. It represents node types with names such as \texttt{`Function}; node data is represented as strings such as \texttt{"x"}.
The output produced by the call at line 7 would be as follows:

\begin{verbatim}
{ `Function{ { `Id "x" },
      { `Return{ `Op{ "add", `Id "x", `Id "y"}}}
}}
\end{verbatim}

Node \texttt{`Id "y"} is internally decorated with a closure that returns the value of \texttt{y} defined in line 4.

\begin{figure}[t]
\begin{verbatim}
 1    local lua2ast = require "lua2ast"
 2    
 3    function boo()
 4        local y = 1
 5        local treesumY = lua2ast.toAST(function(x) return x + y end)
 6        y = y + 1
 7        lua2ast.print(treesumY)
 8        return treesumY
 9    end
10    
11    function foo()	
12        local y = 10
13        local ret = boo()
14        return lua2ast.compile(ret)(40) -- returns 42
15    end
\end{verbatim}
\protect\caption{\label{fig:Lua2ASTExample}Lua2AST usage example}
\end{figure}

\subsection{Function lua2ast.compile(\emph{ast})}

This function takes an AST and returns a new function object that is a result of the AST's compilation.
When used with ASTs generated by \texttt{lua2ast.toAST()}, it will use the additional
decoration to produce variable references with proper lexical scope.

Function \texttt{lua2ast.toAST()} works by generating source code,
compiling it and then using the standard debug library's
facilities to attach the auxiliary closures to the generated function's
upvalue slots.

Proceeding with the example of Figure \ref{fig:Lua2ASTExample}, 
the AST returned in line 13 would be initially converted into the
following source code (Lua uses double-brackets for multi-line strings):

\begin{verbatim}
[[ local y
   return function(x) return x + y() end ]]
\end{verbatim}

Prior to the reconstructed source code of the functions,
we add declarations of local variables for each outer local variable
referenced in the function. Note also that references for these
variables are replaced by function calls in the body of the function.

We then compile this source code using Lua's standard function
\texttt{loadstring()} and run it to obtain its return value: a Lua function object.
Note that in the value of local \texttt{y} is not assigned
in the source code. Calling this function at this point would result
in an error as the upvalue for \texttt{y} points to a variable with
the value of \texttt{nil}.

The final step of \texttt{lua2ast.compile()} is to fix the upvalue
references to make them point to the auxiliary closures created by
\texttt{lua2ast.toAST()} and stored in the AST table.
For that, we use the standard function \texttt{debug.setupvalue()},
which takes a closure, an upvalue index and a Lua value, and sets
the variable pointed by the upvalue to the given value.
It is worth pointing out, however, that by setting this value we are not fixing the value
of the original variable reference, since we replaced it in the newly generated function
with a call to a proxy function, which is being fixed in its stead.
This entire process is formalized in the following section.

Once the upvalues are fixed, \texttt{lua2ast.compile()} returns the
function. In line 14 of Figure \ref{fig:Lua2ASTExample} we see
that the result of the compilation is then further applied,
and the reconstructed function runs according to the scope of the
original function declared in line 5.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semantics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:semantics}

In this section, we specify the behavior of functions \texttt{lua2ast.toAST()}
and \texttt{lua2ast.compile()} by using the formalization of a subset
of Lua semantics, presented in \cite{DeVito2013Terra} as Lua Core.
We use the same formal framework of that work in order to properly
compare and contrast our approach for multi-stage programming to that
employed by Terra.

Lua Core depicts the notions of lexical scoping, closures and side-effects
present in Lua, and is therefore mostly sufficient for our purposes.
We extend this specification with an arbitrary ``binary operator''
expression, mimicking Lua operators supported by Lua2AST. This way,
we have a recursive rule through which we can model Lua expressions
as trees, to be later converted to ASTs. We also include $toAST()$ and
$compile()$ as core language operations so we can specify their semantics
separately from plain functions.

\begin{figure}[t!]
\begin{eqnarray*}
e & = & b\,|\, x\,|\,\mbox{let \ensuremath{x=e}\ in\ \ensuremath{e}}\,|\, x\coloneqq e\,|\, e(e)\,|\,\mbox{fun}(x)\{e\}\,|\, e\mbox{ op }e\,|\,\mbox{toAST}(e)\,|\,\mbox{compile}(a)\\
v & = & b\,|\,\left\langle \Gamma,x,e\right\rangle \,|\, a\\
a & = & [\mbox{fn\ \ensuremath{x}\ \ensuremath{a}}]\,|\,[\mbox{base\ \ensuremath{b}}]\,|\,[\mbox{var}\ x\ \left\langle \Gamma,x,e\right\rangle ]\,|\,[\mbox{op\ \ensuremath{a}\ \ensuremath{a}}]
\end{eqnarray*}
\protect\caption{\label{fig:LuaCoreSyntax}Syntax of our version of Lua Core, extended
with constructs to specify Lua2AST}
\end{figure}


The syntax of our version of Lua Core is presented in Figure \ref{fig:LuaCoreSyntax}.
A Lua expression ($e$) can be either a base value ($b$), a variable
($x$), a scoped variable definition ($\mbox{let \ensuremath{x=e}\ in\ \ensuremath{e}}$,
with $e_{1};e_{2}$ as sugar for $\mbox{let \ensuremath{\_=e_{1}}in \ensuremath{e_{2}}}$),
a variable assignment ($x\coloneqq e$), an application ($e(e)$),
a function definition ($\mbox{fun}(x)\{e\}$), an operation on expressions
($e\mbox{ op }e$), or one of the special invocations \emph{toAST($e$)}
and \emph{compile($a$)}. Lua values ($v$) can be base values ($b$),
Lua ASTs ($a$) or closures. A closure is represented as a triple
$\left\langle \Gamma,x,e\right\rangle $, consisting of a namespace
$\Gamma:x\rightarrow p$ (mapping variable names $x$ to memory positions
$p$), an input argument $x$ and an expression body $e$. A Lua AST
for a function consists of a root node ($[\mbox{fn\ \ensuremath{x}\ \ensuremath{a}}]$)
which may contain nodes that wrap base values\emph{ }($[\mbox{base }b]$\emph{),
}operations ($[\mbox{op}\ a\ a]$), and variables ($[\mbox{var}\ x\ \left\langle \Gamma,x,e\right\rangle ]$).
As we will see below, the fact that variables are wrapped by a node
containing a closure is central to our approach.

\begin{figure}[t!]
{\footnotesize{}}%
\begin{minipage}[t]{0.59\columnwidth}%
{\footnotesize{}
\[
v,\Sigma\overset{L}{\rightarrow}v,\Sigma\textsc{ (LVal)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\Sigma=(\Gamma,S)}{x,\Sigma\overset{L}{\rightarrow}S(\Gamma(x)),\Sigma}\textsc{ (LVar)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
e_{1},\Sigma_{1}\overset{L}{\rightarrow}v_{1},(\Gamma_{2},S_{2})\,\,\,\,\,\,\,\, p\,\mbox{fresh}\\
e_{2},(\Gamma_{2}[x\leftarrow p],S_{2}[p\leftarrow v_{1}])\overset{L}{\rightarrow}v_{2},(\Gamma_{3},S_{3})
\end{array}}{\mbox{let \ensuremath{x=e_{1}}\,\ in\,\ensuremath{e_{2}}},\Sigma_{1}\overset{L}{\rightarrow}v_{2},(\Gamma_{2},S_{3})}\textsc{ (LLet)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
e_{1},\Sigma_{1}\overset{L}{\rightarrow}\left\langle \Gamma_{1},x,e_{3}\right\rangle ,\Sigma_{2}\\
e_{2},\Sigma_{2}\overset{L}{\rightarrow}v_{1},(\Gamma_{3},S_{3})\,\,\,\,\,\,\,\,\mbox{\ensuremath{p}\ fresh}\\
e_{3},(\Gamma_{1}[x\leftarrow p],S_{3}[p\leftarrow v_{1}])\overset{L}{\rightarrow}v_{2},(\Gamma_{4},S_{4})
\end{array}}{e_{1}(e_{2}),\Sigma_{1}\overset{L}{\rightarrow}v_{2},(\Gamma_{3},S_{4})}\textsc{ (LApp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e_{1},\Sigma_{1}\overset{L}{\rightarrow}v,(\Gamma,S)\,\,\,\,\,\,\,\,\Gamma(x)=p}{x\coloneqq e,\Sigma\overset{L}{\rightarrow}v,(\Gamma,S[p\leftarrow v])}\textsc{ (LAsn)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\Sigma=(\Gamma,S)}{\mbox{fun(\ensuremath{x})\{\ensuremath{e}\}},\Sigma\overset{L}{\rightarrow}\left\langle \Gamma,x,e\right\rangle ,\Sigma}\textsc{ (LFun)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
e_{1},\Sigma_{1}\overset{L}{\rightarrow}v_{1},\Sigma_{2}\,\,\,\,\,\,\,\, e_{2},\Sigma_{2}\overset{L}{\rightarrow}v_{2},\Sigma_{3}\\
v_{3}=Op(v_{1},v_{2})
\end{array}}{e_{1}\mbox{\,\ op\,}e_{2},\Sigma_{1}\overset{L}{\rightarrow}v_{3},\Sigma_{3}}\textsc{ (LOp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e_{1},\Sigma_{1}\overset{L}{\rightarrow}\left\langle \Gamma,x,e_{2}\right\rangle ,\Sigma_{2}\,\,\,\,\,\,\,\,\left\langle \Gamma,x,e_{2}\right\rangle ,\Sigma_{2}\overset{D}{\rightarrow}a}{\mbox{toAST(\ensuremath{e_{1}})},\Sigma_{1}\overset{L}{\rightarrow}a,\Sigma_{2}}\textsc{ (LAst)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{a,\Sigma_{1}\overset{C}{\rightarrow}e,\Sigma_{2}\,\,\,\,\, e\overset{L}{\rightarrow}v}{\mbox{compile(\ensuremath{a})},\Sigma_{1}\overset{L}{\rightarrow}v,\Sigma_{2}}\textsc{ (LComp)}
\]
}%
\end{minipage}{\footnotesize{}}%
\begin{minipage}[t]{0.4\columnwidth}%
{\footnotesize{}
\[
b,\Sigma\overset{D}{\rightarrow}[\mbox{base }b]\textsc{ (DBase)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
\Sigma=(\Gamma,S)\end{array}}{x,\Sigma\overset{D}{\rightarrow}[\mbox{var}\ x\ \left\langle \Gamma,\_,x\right\rangle ]}\textsc{ (DVar)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e_{1},\Sigma\overset{D}{\rightarrow}a_{1}\,\,\,\,\,\,\,\, e_{2},\Sigma\overset{D}{\rightarrow}a_{2}}{e_{1}\mbox{ op }e_{2},\Sigma\overset{D}{\rightarrow}[\mbox{op\,\ensuremath{a_{1}\,}\ensuremath{a_{2}}}]}\textsc{ (DOp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e,\Sigma\overset{D}{\rightarrow}a}{\left\langle \Gamma,x,e\right\rangle ,\Sigma\overset{D}{\rightarrow}[\mbox{fn }x\, a]}\textsc{ (DFn)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
[\mbox{base \ensuremath{b}}],\Sigma\overset{C}{\rightarrow}b,\Sigma\textsc{ (CBase)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
\Sigma_{1}=(\Gamma,S)\\
p\,\mbox{fresh}\\
\Sigma_{2}=(\Gamma[x\leftarrow p],S[p\leftarrow f])
\end{array}}{[\mbox{var}\ x\ f],\Sigma_{1}\overset{C}{\rightarrow}x(\_),\Sigma_{2}}\textsc{ (CVar)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{a_{1},\Sigma_{1}\overset{C}{\rightarrow}e_{1},\Sigma_{2}\,\,\,\,\,\,\,\, a_{2},\Sigma_{2}\overset{C}{\rightarrow}e_{2},\Sigma_{3}}{[\mbox{op\,\ensuremath{a_{1}}\ensuremath{\, a_{2}}}],\Sigma_{1}\overset{C}{\rightarrow}e_{1}\mbox{ op }e_{2},\Sigma_{3}}\textsc{ (COp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
\Sigma_{1}=(\Gamma_{1},S_{1})\\
a,\Sigma_{1}\overset{C}{\rightarrow}e,(\Gamma_{2},S_{2})
\end{array}}{[\mbox{fn }x\, a],\Sigma_{1}\overset{C}{\rightarrow}\left\langle \Gamma_{2},x,e\right\rangle ,(\Gamma_{1},S_{2})}\textsc{ (CFn)}
\]
}%
\end{minipage}{\footnotesize \par}

\protect\caption{\label{fig:Semantics}Rules $\protect\overset{L}{\rightarrow}$ for
the evaluation of Lua expressions, $\protect\overset{D}{\rightarrow}$
for decompiling Lua expressions into ASTs, and $\protect\overset{C}{\rightarrow}$
for compiling ASTs back into expressions.}
\end{figure}


In Figure \ref{fig:Semantics}, we present the rules for evaluating
Lua Core over an environment $\Sigma$, which is a tuple $(\Gamma,S)$
containing a namespace $\Gamma:x\rightarrow p$ and a store $S:p\rightarrow v$
that maps memory positions to values%
\footnote{The semantics of Lua Core in \cite{DeVito2013Terra} is based on an
environment $\Sigma=(\Gamma,S,F)$ where $F$ is specific to Terra
functions. In our presentation, we removed $F$. Rules reused from
\cite{DeVito2013Terra} were adapted accordingly.%
}. We use $\overset{L}{\rightarrow}:(e\times\Sigma)\rightarrow(v\times\Sigma)$
for the evaluation of Lua expressions as in \cite{DeVito2013Terra}.
Rules for $\overset{L}{\rightarrow}$ presented here are equivalent
to those in that work: \textsc{LVal} and \textsc{LVar} evaluate values
and variables; \textsc{LLet} describes variable scoping, by evaluating
$e_{2}$ in an environment created by adding the result of evaluating
$e_{1}$ and assigning it to local variable $x$; \textsc{LApp} describes
function application, propagating side effects; \textsc{LAsn} evaluates
assignments; \textsc{LFun} evaluates function declarations. Our work
adds new rules for $\overset{L}{\rightarrow}$: \textsc{LOp} describes
the evaluation of an arbitrary binary operator, with semantics given
by some function $Op()$; \textsc{LAst} describes the evaluation of
$toAST()$; \textsc{LComp} evaluates $compile()$.

We also add two other relations: rules for decompiling a Lua function
into an AST ($\overset{D}{\rightarrow}:(e\times\Sigma)\rightarrow a$)
and rules for compiling ASTs back into Lua functions ($\overset{C}{\rightarrow}:(a\times\Sigma)\rightarrow(e\times\Sigma)$).
These are used in \textsc{LAst} and \textsc{LComp}, respectively.

The decompilation function $\overset{D}{\rightarrow}$ takes an expression
and an environment and produces an AST. Since $toAST()$ is a pure
function, $\Sigma$ does not figure in the codomain of $\overset{D}{\rightarrow}$.
Note that $\overset{D}{\rightarrow}$ is defined only for base values
(\textsc{DBase}), variables (\textsc{DVar}), the binary operator (\textsc{DOp}),
and the initial function (\textsc{DFn}), mirroring the implementation
of \emph{toAST}() in Lua2AST, which only supports functions containing
these elements. Its rules deconstruct the body of the function and
build the corresponding AST. Of particular interest is rule \textsc{DVar},
which stores in the AST node a newly created closure, which returns
the value of $x$ given the original function's environment.

The compilation function $\overset{C}{\rightarrow}$ takes an AST
and an environment and produces a closure and a new environment. For
each of the four decompilation rules there is a complementary compilation
rule: \textsc{CBase}, \textsc{CVar}, \textsc{COp} and \textsc{CFn}.
Rule \textsc{CVar} translates nodes representing variable references
into a function call to the closure created by rule \textsc{DVar}.
\textsc{CVar} assigns this closure to a variable $x$ in the resulting
environment, and produces a function call to this closure instead
of a variable reference. Rule \textsc{CFn} returns a closure representing
the entire compiled function and a new environment. This environment
contains an unmodified namespace $\Gamma_{1}$ and a new store $S_{2}$,
which includes any closures created for keeping variable references.
The extended namespace $\Gamma_{2}$ produced by the compilation is
used as the namespace of the resulting function's closure.

As a result of running $compile()$, all variable references that
existed in the original function that was decompiled and was now recompiled
were replaced by calls to newly-created closures that merely return
the value of the corresponding variables. These closures use the original
namespace from decompilation time ($\Gamma$ in \textsc{DVar}), so
the variable references are bound to the addresses they have in the
lexical scope where decompilation takes place. Any variable $x$ stored
in an AST will only be evaluated when the compiled function returned
by $compile(a)$ is called.

By replacing variable references to function
calls to the wrapper closures, we ensure that the evaluation of variables
(ultimately happening within the wrapper closures) are based on their
original namespaces. This is different from the approach taken by
Terra \cite{DeVito2013Terra}, where evaluation of Lua variables
is done when the Terra code is generated. LINQ \cite{linq} preserves
the lexical scoping of reconstructed function objects like our work does,
but in our case staging happens entirely at run time.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:conclusion}

In this work we presented an approach for multi-stage programming, through
which the lexical scope of variables can be preserved by replacing
variable references in the generated representation of the embedded language
with closures from the host language. When the intermediate representation
is later converted into executable form, calls to these closures are
produced, ensuring access to the variable in the correct context.

We implemented a module that demonstrates this approach.
Our implementation uses a decompiler to convert, at runtime, Lua
functions into an abstract syntax tree form decorated with
closures that capture the lexical environment of free variables.
The module is then able to compile the AST back into Lua,
ensuring that the resulting function accesses the correct variables
even if compiled at a different call site.

The technique we present here is general, and its core principle
is not dependent on specificities of Lua. It could be implemented in other
languages using other methods, such as source code pre-processing. However,
the run-time manipulation of function objects made possible by decompilation,
as opposed to compile-time manipulation of the source tree, allows us to
perform multi-stage programming dynamically, operating on any suitable
functions, even if they were created via dynamic code generation. This makes
our approach particularly suitable for dynamic languages.

Our implementation also exploited Lua's facilities for manipulating
a closure's list of upvalues, which allowed the construction of the
generated functions purely through manipulation of Lua function
objects, without having to resort to low-level bytecode generation.
The only bytecode-level manipulation performed by Lua2AST is
read-only, and is restricted to the decompiler module. Our implementation
required no language extensions and no modifications to the Lua VM.

We also specified the operational semantics for the transformations
performed by Lua2AST, in order to show how the lexical environment
of variables is correctly preserved, and to contrast it with
related work from the literature on multi-stage programming.

This work presents many possibilities for future extensions. The current
implementation is a proof-of-concept that demonstrates the technique,
and can be extended to support more of the host language's grammar. Another future work
we envision is the development of different code-generation back-ends,
supporting other languages. This would allow, for example, using
Lua functions for writing prepared statements for database query
languages.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{splncs_srt}
\bibliography{sblp2015}

\end{document}
