\documentclass[english]{llncs}

\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{babel}

\title{Preserving Lexical Scoping\\
When Dynamically Embedding Languages}

\author{
Félix Ribeiro,
Hisham Muhammad,\\
André Murbach Maidl,
Roberto Ierusalimschy
}

\institute{
Department of Computer Science --
PUC-Rio -- Rio de Janeiro -- Brazil
\email{\{fribeiro,hisham,amaidl,roberto\}@inf.puc-rio.br}
}

\begin{document}

\maketitle

\begin{abstract}

There are various situations in which one may want to embed source code from
one language into another, for example when combining relational query
languages with application code or when performing staged meta-programming.
Typically, one will want to transfer data between these languages.
We propose an approach in which the embedded code shares variables with the
host language, preserving lexical scoping rules even after the code is
converted into an intermediate representation. We demonstrate this approach
through a module for meta-programming using Lua as both embedded and host
languages, which decompiles Lua functions to their AST form and can later
rebuild them preserving scoping rules of the decompilation site. Our method
requires no special annotation of functions to be translated and is
implemented as a library, requiring no source pre-processing or changes to
the host language execution environment.

\keywords{
Lua,
Domain-Specific Languages,
Embedded Languages
}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:introduction}

Domain-Specific Languages (DSLs) are a way to simplify the development
of programs through the aggregation of domain knowledge into a
programming language.
A Domain-Specific Language is a programming language that
includes features to express the semantics of a domain,
often adding specific syntax.
Examples of DSLs are \TeX{} for text processing, MATLAB for performing
numerical computations, SQL for querying relational databases and
regular expressions for pattern matching in text.

The use of DSLs frequently happens in combination with other languages, so
that some aspects of a problem are handled with the DSL while other parts are
developed in a general-purpose language \cite{Fowler:2010:DSL:1809745}. One
way to do this is to embed source code written in the domain-specific language
into the source code of the application, which is written in another language.
We have then the notion of a \emph{host language} and an \emph{embedded language}.
SQL and regular expressions are examples of languages which are often used in this fashion.

Embedding source code of one language into another poses challenges.
Typically, a language parser does not have support for handling
chunks of code written in another language intermixed with the source
code. Common approaches to handle the source code of two languages
in a single source file are to either pull the processing back to a
step prior to the parsing of the main language, using pre-processing,
or to push it forward by storing the code written in the embedded
language as strings in the host language source code, which are
sent to the embedded language for processing only at run time.

This approach of storing code as strings, while popular, has some inconveniences.
For instance, it is not possible to detect syntactical errors while compiling the code.
Embedding languages should also allow programmers to transfer data
between these languages, taking care to keep data in sync.
For these reasons, solutions based on meta-programming, where the
embedded language can be manipulated at a higher level of abstraction
than strings, are more interesting.

Multi-Stage Programming (MSP) \cite{Taha1999MSP,Taha2004gentle,Taha2008gentle}
is a meta-programming approach that helps embedding a programming language in
a host language in a well-organized way.
It defines constructs for quoting and escaping source code
that produce code objects, which are valid objects stored in the host
language but can also be invoked to execute the embedded language.
A major benefit of MSP is that it does not delay error verification to run-time.
One can detect syntactical errors and even type errors in the embedded code
during compile-time.
Another benefit of MSP is that we can use program specialization to
reduce the costs of abstractions \cite{Taha1999MSP}.

Using MSP to embed languages inside imperative languages can be hard,
because in these languages programmers can move code objects so they
are used outside of the scope of the binder of their free variables
\cite{Westbrook2010Mint}.
In purely functional languages we do not have this problem 
due to the absence of side effects \cite{Kameyama2008CSS}.

In this work, we propose an approach for meta-programming
in which the embedded code shares variables with the
host language, preserving lexical scoping rules even after the code is
converted into an intermediate representation.
In our proposed method, the host language uses closures
to share data with the embedded language, replacing variable references
with function calls in the generated code.
This way, we ensure that variables always match the scope of their declarations.

We demonstrate this approach through a module for meta-programming using Lua
as both embedded and host languages.
Our module decompiles Lua functions to their Abstract Syntax Tree (AST) form
and can later rebuild them preserving scoping rules of the decompilation site.
For simplicity, our implementation only supports functions that contain
a single expression.
We call these functions \emph{lambda functions}.

Our method requires no special annotation of functions to be translated and is
implemented as a library, requiring no source pre-processing or changes to
the host language execution environment.
When an AST describes a function that uses variables from an
external local scope, it includes information about the context
where this function was defined.

We organize this paper in five sections.
In Section \ref{sec:related} we review related work in the field
of multi-stage programming.
In Section \ref{sec:lua2ast} we demonstrate our approach.
In Section \ref{sec:semantics} we formalize the semantics of our approach.
In Section \ref{sec:conclusion} we present our conclusions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:related}

Meta-programming is the concept of writing programs that manipulate
program code as data, producing other programs. This allows programmers
to improve code performance or expressiveness by defining transformations over code.
Lisp \cite{McCarthy1960RFS} pioneered meta-programming by introducing
a mechanism of \emph{quotation}: expressions marked with the operator \texttt{'}
are not evaluated, and are treated as data.
Later Lisp dialects like Common Lisp and Scheme include \emph{quasi-quotation},
represented with the operator \texttt{`}, that allows parts of the quoted expression
to be ``escaped'' (with the  \texttt{,} operator). The combination of
quasi-quotation and escaping powers the macro system of those languages \cite{Bawden1999quasiquotation}.
This feature, however, does not preserve scoping rules.

Multi-Stage Programming \cite{Taha1999MSP,Taha2004gentle,Taha2008gentle} is
similar to the quasi-quotation mechanism,
but it takes lexical scoping into account.
It features three constructs that programmers can use to
annotate code: \emph{brackets}, \emph{escape}, and \emph{run}.
We will use MetaOCaml \cite{Calcagno2003implementing}, an OCaml extension
with MSP support through these three staging constructs, to briefly explain
these constructs. \emph{Brackets}, marked with \texttt{.<>.}, avoid the execution of a computation,
constructing an object instead that represents the marked block of code:
\begin{verbatim}
    let x = 1 + 1;;
    let y = .< 1 + 1 >.;;
\end{verbatim}

In the above example, \texttt{x} has type \texttt{int} and \texttt{y} has
type \texttt{int code}. 
This means that the expression \texttt{x + y} is invalid code in MetaOCaml,
as the types of both variables do not match. \emph{Escapes}, marked as \texttt{.\~}, combine small delayed computations for building
bigger ones:
\begin{verbatim}
    let z = .< x + .~y >.;;
\end{verbatim}

Here, the code \texttt{.< x + .\~{}y >.} binds a new delayed computation
\texttt{2 + (1 + 1)} to \texttt{z}. \emph{Run}, using the prefix operator \texttt{.!}, executes staged code.
In the example below, the program will compile and execute the code inside
\texttt{z}, assigning the integer \texttt{4} to \texttt{r}:

\begin{verbatim}
    let r = .!z;;
\end{verbatim}

Implementing DSLs is one of the most interesting applications of MSP \cite{Czarnecki2004DSL}.
Implementing efficient DSLs, either as interpreters or as compilers,
is not an easy task.
The MSP constructs allow programmers to implement a DSL as
a staged interpreter, which translates the DSL code to the host language code,
allowing DSLs to run as efficiently as the host code, taking advantage
of the optimizations of the underlying compiler \cite{Taha2004gentle}.

Mint \cite{Westbrook2010Mint} is a MSP extension to Java.
Even though MSP ensures correctness while embedding languages using
purely functional languages, the same is not that straightforward when
we try to use MSP for embbeding imperative languages.
The problem of embedding a language in an imperative language is
related to side effects, as programmers can move code objects
beyond the bound scope of free variables inadvertedly, a problem
known as scope extrusion.
Mint extends the semantics of the escape construct to impose
some restrictions on side effects, not allowing side effects to
appear inside a escape construct when these side effects interact
with delayed code.

% TODO: Mint example?
% (illustrate scope extrusion problem / how it solves it)

LINQ (Language Integrated-Query) \cite{linq} is a set of features that
extends C\#, allowing programmers to perform queries and manipulate data over
different kinds of data storage such as XML and MDF.
One can also use LINQ with data structures such as lists and arrays.

In .NET, C\# and Visual Basic define a restricted type of anonymous
function called an \emph{expression lambda}, which is a function that
consists of a single expression. LINQ works as an embedded DSL
\cite{Fowler:2010:DSL:1809745} where anonymous functions are used
extensively, and was the motivating use case for the introduction
of expression lambdas. When one assigns an expression lambda to a variable
of type \texttt{Expression<TDelegate>}, .NET creates an AST
corresponding to that expression, called an \emph{expression tree}
\footnote{Note that in C\# parlance, \emph{lambda expression} is a
more general term that can refer to both single-expression anonymous functions
called \emph{expression lambdas} and multi-statement functions called
\emph{statement lambdas}. Conversion to expression trees is only supported for
expression lambdas.}. Expression trees can also be created 
programatically, manipulating node objects via the API of the
\texttt{Expression} class.

\begin{figure}[t]
\begin{verbatim}
 1    class Program {
 2      delegate int sumY (int arg);
 3      Expression <sumY> boo () {
 4        int y = 1;
 5        Expression <sumY> treesumY = x => x + y;
 6        y = y + 1;
 7        return treesumY;
 8      }
 9      void foo () {
10        int y = 10;
11        Expression <sumY> ret = boo();
12        int res = ret.Compile()(40); // res is 42
13      }
14    }
\end{verbatim}
\protect\caption{\label{fig:ExpressionTrees}Lexical scoping in variables
referenced in expression trees in C\#.}
\end{figure}

Expression lambdas can access external local variables, and they respect
lexical scope, regardless if they are used to declare anonymous functions or
only to produce an expression tree. Figure
\ref{fig:ExpressionTrees} illustrates how lexical scoping is preserved in
expression trees. Free variable \texttt{y} in line 5 references the declaration
from line 4, even when the expression tree returned in line 11 is compiled
into a function in line 12.

Terra \cite{DeVito2013Terra} is a multi-stage language for high-performance
computing. It uses Lua as a host language and defines extensions
for staged computation. Lua functions that run in the Lua interpreter are
declared using standard Lua syntax, with the \texttt{function} construct.
Staged code is declared as Terra functions, using the \texttt{terra}
statement. Terra functions use similar syntax to Lua, but they are statically
typed and compiled into native code using LLVM. Lua code can manipulate Terra
types and functions as Lua objects. Terra also features a \texttt{quote} statement
for quoting blocks of Terra code as expression objects and brackets
(\texttt{[]}) as the escape operator for evaluating Lua code inside a Terra
function.

When a Terra function is declared, all Lua expressions escaped inside it
and Lua variables are replaced by the results of their evaluation.
A Terra function, therefore, does not form a closure with
respect to free Lua variables. This design trades lexical scoping for the
guarantee that compiled Terra code does not need to call back into the Lua
interpreter during execution.

Metalua \cite{metalua} is a Lua compiler that supports compile-time
meta-programming, a mechanism that allows programmers to interact
with the compiler through a macro system \cite{Fleutot2007contrasting}.
Metalua extends Lua 5.1 to provide methods for transforming Lua
code into Abstract Syntax Trees, but this code cannot contain
references to local variables of an outer scope.

Our implementation generates program ASTs in the same format as
Metalua, but including information about enclosing local variables. While Metalua
handles arbitrary Lua code syntactically marked for quoting, our module
operates only on restricted functions, but requires no quoting.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Lua2AST}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:lua2ast}

Lua2AST is a Lua module that takes a restricted form of Lua function, that we named lambda functions, and generates its AST in runtime.
Lambda functions are defined here as functions that only contain the return statement.
The expression contained in the return statement can be of any kind and can also use variables of the outer lexical scope.
In Lua, a function variable of outer lexical scope is called \emph{upvalue}\cite{Ierusalimschy2006PIL} due to historical reasons.
% TODO: explain upvalues, \cite{Ierusalimschy2006PIL}

Lua2AST uses external libraries: luadec and lua-parser.
Lua-parser \cite{lua-parser} generates a Lua AST from a string with a valid Lua code.
Luadec \cite{luadec} is a Lua decompiler that takes a Lua binary chunk and returns a string with equivalent code.

One big difference from this work to the related works is that our implementation is done via library and we do not use a preprocessor.
Since a decompiler is used, there is no need to modify the Lua's virtual machine source code.
Instead, the library takes a runtime binary chunk and uses the decompiler to get an equivalent code.


Lua is a dynamic language and has powerfull features like \texttt{dostring} function, that executes a given string as a Lua chunk.
For example, we can use a user string input in a form of Lua code and use \texttt{dostring} in order to execute this input inside a running program.
Since our method is done at runtime, with no syntax modification then preprocessors are not required, so functions as \texttt{dostring} may still be used.



This module contains two principal functions: \texttt{toAST} and \texttt{compile}.
The first one generates an AST and the second one compiles an AST.

\subsection{Function toAST(func) }


The function \texttt{toAST} generates an AST from a Lua function.
The parameter \texttt{func} must be a lambda function.
The function's return is a Lua table that represents an AST.
If the received function uses upvalues the returned table will be a decorated AST, so that the upvalues can be evaluated properly.

The function \texttt{toAST} calls the function \texttt{luadec} that belongs to \texttt{libluadec}.
\texttt{toAST} sends the received function to \texttt{luadec}. 
The return of the \texttt{luadec} is a string that represents the passed function code.
This string is sent to the parse function of \texttt{lua-parser} library and it returns the AST that represents the code.

\texttt{toAST} traverses the received AST once.
Firstly we find the parameters of the function and store them in a set.
Later, we locate the free variables of the function.
For each located variable we make a code lookup with the standard debug library.
The lookup consists in finding a variable of outer lexical scope with the same name.
When the variable is found, we do the AST's decoration process.

To do this decoration in our AST we use the function \texttt{upvaluejoin}, that also belongs to the debug library.
This function gets an upvalue from a Lua closure and make it refer to a desirable upvalue.
So, in order to use this function, we need to create a Lua closure with an upvalue.
To do so, we present the following function:


\begin{verbatim}
local function newclosure()
    local temp
    return function () return temp end
end
\end{verbatim}

So, when we find an upvalue, we call \texttt{newclosure} function.
Then its return is assigned to a variable and the found upvalue is joined to the \texttt{temp} upvalue.
After pulling them together, we replace in the AST the node that identifies the free variable by the function returned by \texttt{newclosure}.


Figure \ref{fig:Lua2ASTExemple} illustrates the use of the toAST function.
The Lua code on this example does the same as the code on example of Figure \ref{fig:ExpressionTrees}.
In addition, the command \texttt{last.print} dumps the AST in textual format, following the syntax defined by Metalua \cite{metalua}.
It represents node types with uppercase names such as `Function; node data is represented as strings such as "x".
The output of \texttt{last.print} will be as follows:
%% Verificar higienizacao de variaveis
\begin{verbatim}
{ `Function{ { `Id "x" },
      { `Return{ `Op{ "add", `Id "x", `UpValue "y"}}}}}}
\end{verbatim}


\begin{figure}[t]
\begin{verbatim}
 1    local last = require "lua-to-AST"
 2    
 3    function boo()
 4        local y = 1
 5        local treesumY = last.toAST(function(x) return x + y end )
 6        y = y + 1
 7        last.print(treesumY)
 8        return treesumY
 9    end
10    
11    function foo()	
12        y = 10
13        ret = boo()
14        f = last.compile(ast)
15        print(f(40)) -- output: 42
16    end
\end{verbatim}
\protect\caption{\label{fig:Lua2ASTExemple}Lua2AST usage example}
\end{figure}

\subsection{Function compile(ast) }

% explicar que ele retorna uma NOVA função. do jeito que está escrito parece que ele faz lookup.
This function returns a new function that is a result of the AST's compilation. 
The AST might be previously generated by toAST.


% O que é um return node? não entendi.
The received AST is encapsulated in an AST's return node.
Then, in a code generation process, a string with correspondent Lua code is created.
Using the AST above to examplify, its correspondent string would be as follows:

%% TODO : higenizacao
\begin{verbatim}
[[ do 
   local y=0 
   return function(x) return x + y end 
   end ]]
\end{verbatim}

This string is sent to the \texttt{loadstring} function.
This last one is a Lua standard function that returns a function in order to execute a string in a form of Lua code.
Then, we use \texttt{debug.upvaluejoin} to bind the upvalues from the generated code with the upvalues of the closure stored in the AST.
This mechanism ensures the code hygienization.
After the bindings \texttt{compile} returns the function.

In this way the user can use the returned function, that is the compilation of the AST.
We can see the usage of the \texttt{compile} function in the line 14 of the figure \ref{fig:Lua2ASTExemple}.
It uses the AST that was generated in line 5 by \texttt{toAST}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semantics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:semantics}

In this section, we specify the behavior of $toAST()$ and $compile()$
by using the formalization of a subset of Lua semantics, presented
in \cite{DeVito2013Terra} as Lua Core. We use the same formal framework
of that work in order to properly compare and contrast our approach
for multi-stage programming to that employed by Terra.

Lua Core depicts the notions of lexical scoping, closures and side-effects
present in Lua, and is therefore mostly sufficient for our purposes.
We extend this specification with an arbitrary \emph{binary operator}
expression, mimicking Lua operators supported by Lua2AST. This way,
we have a recursive rule through which we can model Lua expressions
as trees, to be later converted to ASTs. We also include $toAST()$ and
$compile()$ as core language operations so we can specify their semantics
separately from plain functions.

\begin{figure}[t]
\begin{eqnarray*}
e & = & b\,|\, x\,|\,\mbox{let \ensuremath{x=e}\,\ in\,\ensuremath{e}}\,|\, x\coloneqq e\,|\, e(e)\,|\,\mbox{fun}(x)\{e\}\,|\, e\mbox{ op }e\,|\,\mbox{toAST}(e)\,|\,\mbox{compile}(a)\\
v & = & b\,|\,\left\langle \Gamma,x,e\right\rangle \,|\, a\\
a & = & [\mbox{fn\,\ensuremath{x}\,\ensuremath{a}}]\,|\,[\mbox{base \ensuremath{b}}]\,|\,[\mbox{var}\,\left\langle \Gamma,x,e\right\rangle ]\,|\,[\mbox{op\,\ensuremath{a}\,\ensuremath{a}}]
\end{eqnarray*}
\protect\caption{\label{fig:LuaCoreSyntax}Syntax of our version of Lua Core, extended
with constructs to specify Lua2AST}
\end{figure}


The syntax of our version of Lua Core is presented in Figure \ref{fig:LuaCoreSyntax}.
A Lua expression ($e$) can be either a base value ($b$), a variable
($x$), a scoped variable definition ($\mbox{let \ensuremath{x=e}\ in\ \ensuremath{e}}$,
with $e_{1};e_{2}$ as sugar for $\mbox{let \ensuremath{\_=e_{1}} in \ensuremath{e_{2}}}$),
a variable assignment ($x\coloneqq e$), an application ($e(e)$),
a function definition ($\mbox{fun}(x)\{e\}$), an operation on expressions
($e\mbox{ op }e$), or one of the special invocations \emph{toAST($e$)}
and \emph{compile($a$)}. Lua values ($v$) can be base values ($b$),
Lua ASTs ($a$) or closures. A closure is represented as a triple
$\left\langle \Gamma,x,e\right\rangle $, consisting of a namespace
$\Gamma:x\rightarrow p$ (mapping variable names $x$ to memory positions
$p$), an input argument $x$ and an expression body $e$. A Lua AST
for a function consists of a root node ($[\mbox{fn\,\ensuremath{x}\,\ensuremath{a}}]$)
which may contain nodes that wrap base values\emph{ }($[\mbox{base }b]$\emph{),
}operations ($[\mbox{op}\, a\, a]$), and variables ($[\mbox{var }\left\langle \Gamma,x,e\right\rangle ]$).
As we will see below, the fact that variables are wrapped by a node
containing a closure is central to our approach.

\begin{figure}[t!]
{\footnotesize{}}%
\begin{minipage}[t]{0.59\columnwidth}%
{\footnotesize{}
\[
v,\Sigma\overset{L}{\rightarrow}v,\Sigma\textsc{ (LVal)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\Sigma=(\Gamma,S)}{x,\Sigma\overset{L}{\rightarrow}S(\Gamma(x)),\Sigma}\textsc{ (LVar)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
e_{1},\Sigma_{1}\overset{L}{\rightarrow}v_{1},(\Gamma_{2},S_{2})\,\,\,\,\,\,\,\, p\,\mbox{fresh}\\
e_{2},(\Gamma_{2}[x\leftarrow p],S_{2}[p\leftarrow v_{1}])\overset{L}{\rightarrow}v_{2},(\Gamma_{3},S_{3})
\end{array}}{\mbox{let \ensuremath{x=e_{1}}\,\ in\,\ensuremath{e_{2}}},\Sigma_{1}\overset{L}{\rightarrow}v_{2},(\Gamma_{2},S_{3})}\textsc{ (LLet)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
e_{1},\Sigma_{1}\overset{L}{\rightarrow}\left\langle \Gamma_{1},x,e_{3}\right\rangle ,\Sigma_{2}\\
e_{2},\Sigma_{2}\overset{L}{\rightarrow}v_{1},(\Gamma_{3},S_{3})\,\,\,\,\,\,\,\,\mbox{\ensuremath{p}\ fresh}\\
e_{3},(\Gamma_{1}[x\leftarrow p],S_{3}[p\leftarrow v_{1}])\overset{L}{\rightarrow}v_{2},(\Gamma_{4},S_{4})
\end{array}}{e_{1}(e_{2}),\Sigma_{1}\overset{L}{\rightarrow}v_{2},(\Gamma_{3},S_{4})}\textsc{ (LApp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e_{1},\Sigma_{1}\overset{L}{\rightarrow}v,(\Gamma,S)\,\,\,\,\,\,\,\,\Gamma(x)=p}{x\coloneqq e,\Sigma\overset{L}{\rightarrow}v,(\Gamma,S[p\leftarrow v])}\textsc{ (LAsn)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\Sigma=(\Gamma,S)}{\mbox{fun(\ensuremath{x})\{\ensuremath{e}\}},\Sigma\overset{L}{\rightarrow}\left\langle \Gamma,x,e\right\rangle ,\Sigma}\textsc{ (LFun)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
e_{1},\Sigma_{1}\overset{L}{\rightarrow}v_{1},\Sigma_{2}\,\,\,\,\,\,\,\, e_{2},\Sigma_{2}\overset{L}{\rightarrow}v_{2},\Sigma_{3}\\
v_{3}=Op(v_{1},v_{2})
\end{array}}{e_{1}\mbox{\,\ op\,}e_{2},\Sigma_{1}\overset{L}{\rightarrow}v_{3},\Sigma_{3}}\textsc{ (LOp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e_{1},\Sigma_{1}\overset{L}{\rightarrow}\left\langle \Gamma,x,e_{2}\right\rangle ,\Sigma_{2}\,\,\,\,\,\,\,\,\left\langle \Gamma,x,e_{2}\right\rangle ,\Sigma_{2}\overset{D}{\rightarrow}a}{\mbox{toAST(\ensuremath{e_{1}})},\Sigma_{1}\overset{L}{\rightarrow}a,\Sigma_{2}}\textsc{ (LAst)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{a,\Sigma_{1}\overset{C}{\rightarrow}e,\Sigma_{2}\,\,\,\,\, e\overset{L}{\rightarrow}v}{\mbox{compile(\ensuremath{a})},\Sigma_{1}\overset{L}{\rightarrow}v,\Sigma_{2}}\textsc{ (LComp)}
\]
}%
\end{minipage}{\footnotesize{}}%
\begin{minipage}[t]{0.4\columnwidth}%
{\footnotesize{}
\[
b,\Sigma\overset{D}{\rightarrow}[\mbox{base }b]\textsc{ (DBase)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
\Sigma=(\Gamma,S)\end{array}}{x,\Sigma\overset{D}{\rightarrow}[\mbox{var }\left\langle \Gamma,\_,x\right\rangle ]}\textsc{ (DVar)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e_{1},\Sigma\overset{D}{\rightarrow}a_{1}\,\,\,\,\,\,\,\, e_{2},\Sigma\overset{D}{\rightarrow}a_{2}}{e_{1}\mbox{ op }e_{2},\Sigma\overset{D}{\rightarrow}[\mbox{op\,\ensuremath{a_{1}\,}\ensuremath{a_{2}}}]}\textsc{ (DOp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{e,\Sigma\overset{D}{\rightarrow}a}{\left\langle \Gamma,x,e\right\rangle ,\Sigma\overset{D}{\rightarrow}[\mbox{fn }x\, a]}\textsc{ (DFn)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
[\mbox{base \ensuremath{b}}],\Sigma\overset{C}{\rightarrow}b,\Sigma\textsc{ (CBase)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
\Sigma_{1}=(\Gamma,S)\\
p\,\mbox{fresh}\,\,\,\,\, x'\,\mbox{fresh}\\
\Sigma_{2}=(\Gamma[x'\leftarrow p],S[p\leftarrow f])
\end{array}}{[\mbox{var }f],\Sigma_{1}\overset{C}{\rightarrow}x'(\_),\Sigma_{2}}\textsc{ (CVar)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{a_{1},\Sigma_{1}\overset{C}{\rightarrow}e_{1},\Sigma_{2}\,\,\,\,\,\,\,\, a_{2},\Sigma_{2}\overset{C}{\rightarrow}e_{2},\Sigma_{3}}{[\mbox{op\,\ensuremath{a_{1}}\ensuremath{\, a_{2}}}],\Sigma_{1}\overset{C}{\rightarrow}e_{1}\mbox{ op }e_{2},\Sigma_{3}}\textsc{ (COp)}
\]
}{\footnotesize \par}

{\footnotesize{}
\[
\frac{\begin{array}[t]{c}
\Sigma_{1}=(\Gamma_{1},S_{1})\\
a,\Sigma_{1}\overset{C}{\rightarrow}e,(\Gamma_{2},S_{2})
\end{array}}{[\mbox{fn }x\, a],\Sigma_{1}\overset{C}{\rightarrow}\left\langle \Gamma_{2},x,e\right\rangle ,(\Gamma_{1},S_{2})}\textsc{ (CFn)}
\]
}%
\end{minipage}{\footnotesize \par}

\protect\caption{\label{fig:Semantics}Rules $\protect\overset{L}{\rightarrow}$ for
the evaluation of Lua expressions, $\protect\overset{D}{\rightarrow}$
for decompiling Lua expressions into ASTs, and $\protect\overset{C}{\rightarrow}$
for compiling ASTs back into expressions.}
\end{figure}


In Figure \ref{fig:Semantics}, we present the rules for evaluating
Lua Core over an environment $\Sigma$, which is a tuple $(\Gamma,S)$
containing a namespace $\Gamma:x\rightarrow p$ and a store $S:p\rightarrow v$
that maps memory positions to values%
\footnote{The semantics of Lua Core in \cite{DeVito2013Terra} is based on an
environment $\Sigma=(\Gamma,S,F)$ where $F$ is specific to Terra
functions. In our presentation, we removed $F$. Rules reused from
\cite{DeVito2013Terra} were adapted accordingly.%
}.

We use $\overset{L}{\rightarrow}:(e\times\Sigma)\rightarrow(v\times\Sigma)$
for the evaluation of Lua expressions as in \cite{DeVito2013Terra}.
Rules for $\overset{L}{\rightarrow}$ presented here are equivalent
to those in that work: \textsc{LVal} and \textsc{LVar} evaluate values
and variables; \textsc{LLet} describes variable scoping, by evaluating
$e_{2}$ in an environment created by adding the result of evaluating
$e_{1}$ and assigning it to local variable $x$; \textsc{LApp} describes
function application, propagating side effects; \textsc{LAsn} evaluates
assignments; \textsc{LFun} evaluates function declarations. Our work
adds new rules for $\overset{L}{\rightarrow}$: \textsc{LOp} describes
the evaluation of an arbitrary binary operator, with semantics given
by some function $Op()$; \textsc{LAst} describes the evaluation of
$toAST()$; \textsc{LComp} evaluates $compile()$.

We also add two other relations: rules for decompiling a Lua function
into an AST ($\overset{D}{\rightarrow}:(e\times\Sigma)\rightarrow a$)
and rules for compiling ASTs back into Lua functions ($\overset{C}{\rightarrow}:(a\times\Sigma)\rightarrow(e\times\Sigma)$).
These are used in \textsc{LAst} and \textsc{LComp}, respectively.

The decompilation function $\overset{D}{\rightarrow}$ takes an expression
and an environment and produces an AST. Since $toAST()$ is a pure
function, $\Sigma$ does not figure in the codomain of $\overset{D}{\rightarrow}$.
Note that $\overset{D}{\rightarrow}$ is defined only for base values
(\textsc{DBase}), variables (\textsc{DVar}), the binary operator (\textsc{DOp}),
and the initial function (\textsc{DFn}), mirroring the implementation
of $toAST()$ in Lua2AST, which only supports functions containing
these elements. Its rules deconstruct the body of the function and
build the corresponding AST. Of particular interest is rule \textsc{DVar},
which stores in the AST node a newly created closure, which returns
the value of $x$ given the original function's environment.

The compilation function $\overset{C}{\rightarrow}$ takes an AST
and an environment and produces a closure and a new environment. For
each of the four decompilation rules there is a complementary compilation
rule: \textsc{CBase}, \textsc{CVar}, \textsc{COp} and \textsc{CFn}.
Rule \textsc{CVar} translates nodes representing variable references
into a function call to the closure created by rule \textsc{DVar}.
\textsc{CVar} assigns this closure to a new variable $x'$, guaranteed
to be an unused symbol, to maintain hygiene. Rule \textsc{CFn} returns
a closure representing the entire compiled function and a new environment.
This environment contains an unmodified namespace $\Gamma_{1}$ and
a new store $S_{2}$, which includes any closures created for keeping
variable references.

As a result of running $compile()$, all variable references that
existed in the original function that was decompiled and was now recompiled
were replaced by calls to newly-created closures that merely return
the value of the corresponding variables. These closures use the original
namespace from decompilation time ($\Gamma$ in \textsc{DVar}), so
the variable references are bound to the addresses they have in the
lexical scope where decompilation takes place. Any variable $x$ stored
in an AST will only be evaluated when the compiled function returned
by $compile(a)$ is called, and the call to wrapper closure $x'()$
(produced by \textsc{CVar}) will ensure that $x$ is tied to its original
namespace.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:conclusion}

In this work we presented an approach for multi-stage programming through
which the lexical scope of variables can be preserved, by replacing
variable references in the generated representation of the embedded language
with closures from the host language. When the intermediate representation
is later converted into executable form, calls to these closures are
produced, ensuring access to the variable in the correct context.

We implemented a module that demonstrates this approach.
Our implementation uses a decompiler to convert, at runtime, Lua
functions into an abstract syntax tree form decorated with
closures that capture the lexical environment of free variables.
The module is then able to compile the AST back into Lua,
ensuring that the resulting function accesses the correct variables
even if compiled at a different call site.

The technique we present here is general, and its core principle
is not dependent on decompilation or on specificities of Lua.
It could be implemented in other languages using other methods,
such as source code pre-processing. However, the dynamic manipulation
of function objects, as opposed to compile-time manipulation of the
source tree, allows us to perform multi-stage programming dynamically,
operating on any suitable functions, even if they were created at run-time.
This is particularly useful for dynamic languages which provide
\texttt{eval}-like functionality, as is the case of Lua, with
the \texttt{dostring()} function of its standard library.

Our implementation also exploited Lua's facilities for manipulating
a closure's symbol table, which allowed the construction of the
generated functions purely through manipulation of Lua function
objects, without having to resort to low-level bytecode generation.
The only bytecode-level manipulation performed by Lua2AST is
read-only, and is restricted to the decompiler module. The
implementation did not require any modifications to the Lua VM.

We also specified the operational semantics for the transformations
performed by Lua2AST, in order to show how the lexical environment
of variables is correctly preserved, and to properly contrast it with
related work from the literature on multi-stage programming.

This work presents many possibilities for future extensions. The current
implementation is a proof-of-concept that demonstrates the technique,
and can be extended to support a wider range of Lua functions, by
supporting more of the host language's grammar. Another future work
we envision is the development of different code-generation back-ends,
supporting other languages. This would allow, for example, using
Lua functions for writing prepared statements for database query
languages.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{splncs_srt}
\bibliography{sblp2015}

\end{document}
